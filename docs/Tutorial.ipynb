{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e25c5e58",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- Python 3.9+ with the repo cloned locally\n",
    "- `pip install -r requirements.txt` run at the repo root\n",
    "- Optional GPU (the demo works on CPU for the toy dataset)\n",
    "\n",
    "This notebook assumes it lives in the project root or the `docs/` folder shipped with the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b57c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Environment bootstrap ---\n",
    "import os, sys, json, pprint\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path('..').resolve() if Path.cwd().name == 'docs' else Path('.')\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "print(f'Project root set to: {PROJECT_ROOT}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621b9516",
   "metadata": {},
   "source": [
    "## 1. Load Sample Documents\n",
    "Use the built-in `data/example` folder so the walkthrough works out-of-the-box. The `DataProcessor` handles encoding detection, validation, and train/test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f82c1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.config import ConfigManager\n",
    "from backend.data_processor import DataProcessor\n",
    "\n",
    "config = ConfigManager(str(PROJECT_ROOT / 'config' / 'settings.yaml'))\n",
    "processor = DataProcessor(config)\n",
    "example_dir = PROJECT_ROOT / 'data' / 'example'\n",
    "example_files = [str(p) for p in example_dir.glob('*.*')]\n",
    "\n",
    "processed_data = processor.process_uploaded_files(example_files)\n",
    "train_data, test_data = processor.split_data(processed_data)\n",
    "\n",
    "print(f'Documents loaded: {len(processed_data.texts)}')\n",
    "print(f'Train/Test split: {len(train_data.texts)} / {len(test_data.texts)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7133ee8",
   "metadata": {},
   "source": [
    "## 2. Spin Up the Application Core\n",
    "`RFTApplication` mirrors the Gradio UI logic. We reuse `process_uploaded_files` to populate in-memory state exactly the way the interface expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e75806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from frontend.app_core import RFTApplication\n",
    "\n",
    "app = RFTApplication(str(PROJECT_ROOT / 'config' / 'settings.yaml'))\n",
    "upload_summary = app.process_uploaded_files(example_files)\n",
    "\n",
    "pprint.pprint(upload_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff6371e",
   "metadata": {},
   "source": [
    "## 3. Inspect Predictions\n",
    "Grab the next document queued for labeling, check the model's guess, and visualize the metadata you would normally see inside the Gradio labeling tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196c928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "document, doc_payload = app.get_next_document()\n",
    "\n",
    "print('--- Document Preview ---')\n",
    "print(document[:500], '...')\n",
    "\n",
    "print('\n",
    "--- Model Prediction ---')\n",
    "pprint.pprint(doc_payload['prediction'])\n",
    "print(f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455fe7aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
